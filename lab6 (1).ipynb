{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "800ae122-da39-473c-95f5-2bed5f2e83f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "610068f6-4b47-49b2-93b7-a7a4d10b1dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef7d0f31-e60d-420f-ba00-be81e42f730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.Flatten()  # Convert to feature vector\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5e47f6e-53d5-4936-bcca-071e15320c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (50000, 32, 32, 3), Labels shape: (50000, 1)\n",
      "Test data shape: (10000, 32, 32, 3), Labels shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Print dataset shapes\n",
    "print(f\"Training data shape: {x_train.shape}, Labels shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {x_test.shape}, Labels shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50e7d842-de4f-44b8-982d-3306e860b4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New training labels shape: (50000,)\n",
      "New test labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Normalize pixel values to [0,1] range\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Flatten labels (convert shape from (samples, 1) to (samples,))\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()\n",
    "\n",
    "# Print shapes after preprocessing\n",
    "print(f\"New training labels shape: {y_train.shape}\")\n",
    "print(f\"New test labels shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "366738cf-20fd-4b36-9dd7-eeda59d6fa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SWAGA\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,248</span> (364.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m93,248\u001b[0m (364.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,248</span> (364.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m93,248\u001b[0m (364.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 76ms/step - accuracy: 0.0850 - loss: 8.4854 - val_accuracy: 0.1014 - val_loss: 7.6246\n",
      "Epoch 2/2\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 83ms/step - accuracy: 0.1014 - loss: 7.6246 - val_accuracy: 0.1014 - val_loss: 7.6246\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The layer sequential_1 has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m cnn_model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)  \u001b[38;5;66;03m# Must train before extraction!\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Step 2: Extract Features using the trained CNN from Flatten layer\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m feature_extractor \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m\u001b[43mcnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m, outputs\u001b[38;5;241m=\u001b[39mcnn_model\u001b[38;5;241m.\u001b[39mget_layer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_layer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39moutput)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Step 3: Get extracted features\u001b[39;00m\n\u001b[0;32m     50\u001b[0m train_features \u001b[38;5;241m=\u001b[39m feature_extractor\u001b[38;5;241m.\u001b[39mpredict(x_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\ops\\operation.py:254\u001b[0m, in \u001b[0;36mOperation.input\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    246\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124;03m        Input tensor or list of input tensors.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_tensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\ops\\operation.py:285\u001b[0m, in \u001b[0;36mOperation._get_node_attribute_at_index\u001b[1;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has never been called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m     )\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes) \u001b[38;5;241m>\u001b[39m node_index:\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    291\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at node \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the operation has only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inbound nodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    294\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: The layer sequential_1 has never been called and thus has no defined input."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define CNN model for feature extraction\n",
    "base_model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.Flatten()  # Converts to feature vector\n",
    "])\n",
    "\n",
    "# Show model summary\n",
    "base_model.summary()\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load and preprocess CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize images\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()  # Flatten labels\n",
    "\n",
    "# Define CNN model\n",
    "def create_cnn():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.Flatten(name=\"feature_layer\"),  # Extract features from this layer\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Step 1: Build and Train CNN\n",
    "cnn_model = create_cnn()\n",
    "cnn_model.fit(x_train, y_train, epochs=2, batch_size=64, validation_split=0.2)  # Must train before extraction!\n",
    "\n",
    "# Step 2: Extract Features using the trained CNN from Flatten layer\n",
    "feature_extractor = models.Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(\"feature_layer\").output)\n",
    "\n",
    "# Step 3: Get extracted features\n",
    "train_features = feature_extractor.predict(x_train, batch_size=64)\n",
    "test_features = feature_extractor.predict(x_test, batch_size=64)\n",
    "\n",
    "# Step 4: Normalize extracted features\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "# Step 5: Train a Random Forest Classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(train_features, y_train)\n",
    "y_pred = classifier.predict(test_features)\n",
    "\n",
    "# Step 6: Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Random Forest Classification Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bab470-31c8-436a-9572-a42104a95271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\program files\\python312\\lib\\site-packages\\vboxapi-1.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (2.18.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (1.5.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.21.12)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.41.3)\n",
      "Requirement already satisfied: rich in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\swaga\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 43ms/step - accuracy: 0.2976 - loss: 1.8800 - val_accuracy: 0.5088 - val_loss: 1.3598\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.5314 - loss: 1.3111 - val_accuracy: 0.5792 - val_loss: 1.1713\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 32ms/step - accuracy: 0.6054 - loss: 1.1201 - val_accuracy: 0.6259 - val_loss: 1.0652\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.6477 - loss: 0.9904 - val_accuracy: 0.6574 - val_loss: 0.9893\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 34ms/step - accuracy: 0.6829 - loss: 0.9045 - val_accuracy: 0.6529 - val_loss: 0.9971\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow scikit-learn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ✅ Step 1: Load and preprocess CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize images\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()  # Flatten labels\n",
    "\n",
    "# ✅ Step 2: Define CNN Model (Using Functional API for Stability)\n",
    "def create_cnn():\n",
    "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Flatten()(x)  # Feature extraction layer\n",
    "    x = layers.Dense(128, activation='relu', name=\"feature_layer\")(x)  # ✅ Feature Layer\n",
    "    outputs = layers.Dense(10, activation='softmax')(x)  # ✅ Output Layer\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)  # ✅ Using Functional API\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ✅ Step 3: Build & Train CNN Model (Must Train First)\n",
    "cnn_model = create_cnn()\n",
    "cnn_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)  # ✅ Train longer for better accuracy\n",
    "\n",
    "# ✅ Step 4: Fix \"Layer has never been called\" Error by Running a Dummy Forward Pass\n",
    "dummy_input = np.random.rand(1, 32, 32, 3).astype(np.float32)  # ✅ Dummy Data\n",
    "cnn_model.predict(dummy_input)  # ✅ Call the model once to initialize it\n",
    "\n",
    "# ✅ Step 5: Extract Features from the Correct Layer\n",
    "feature_extractor = models.Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(\"feature_layer\").output)\n",
    "\n",
    "# ✅ Step 6: Get extracted features\n",
    "train_features = feature_extractor.predict(x_train, batch_size=64)\n",
    "test_features = feature_extractor.predict(x_test, batch_size=64)\n",
    "\n",
    "# ✅ Step 7: Normalize extracted features\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "# ✅ Step 8: Train a Random Forest Classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(train_features, y_train)\n",
    "y_pred = classifier.predict(test_features)\n",
    "\n",
    "# ✅ Step 9: Evaluate Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Random Forest Classification Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e18cd573-5cce-4608-80e3-4f4e07c855f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Reload CIFAR-10 dataset (Fix missing variables)\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()  # ✅ Reload dataset\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # ✅ Normalize images\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()  # ✅ Flatten labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86d27ae2-28dd-413d-924b-8c0a84388b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 58ms/step - accuracy: 0.3035 - loss: 1.8678 - val_accuracy: 0.5022 - val_loss: 1.3701\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 56ms/step - accuracy: 0.5276 - loss: 1.3272 - val_accuracy: 0.5864 - val_loss: 1.1671\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 59ms/step - accuracy: 0.5989 - loss: 1.1349 - val_accuracy: 0.6256 - val_loss: 1.0857\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 53ms/step - accuracy: 0.6393 - loss: 1.0277 - val_accuracy: 0.6402 - val_loss: 1.0210\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - accuracy: 0.6693 - loss: 0.9494 - val_accuracy: 0.6722 - val_loss: 0.9542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1bd158c8dd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "# ✅ Define CNN Model Again\n",
    "def create_cnn():\n",
    "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Flatten()(x)  # Feature extraction layer\n",
    "    x = layers.Dense(128, activation='relu', name=\"feature_layer\")(x)  # ✅ Feature Layer\n",
    "    outputs = layers.Dense(10, activation='softmax')(x)  # ✅ Output Layer\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ✅ Train CNN Model Again\n",
    "cnn_model = create_cnn()\n",
    "cnn_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)  # ✅ Train CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ba71325-65cc-4d1d-828b-c0eea576bdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step\n"
     ]
    }
   ],
   "source": [
    "# ✅ Extract Features using the trained CNN\n",
    "feature_extractor = models.Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(\"feature_layer\").output)\n",
    "\n",
    "# ✅ Get extracted features for both training and test sets\n",
    "train_features = feature_extractor.predict(x_train, batch_size=64)\n",
    "test_features = feature_extractor.predict(x_test, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42cbcf7b-c110-4691-9dbe-a69323506be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.3038 - loss: 1.8771 - val_accuracy: 0.5122 - val_loss: 1.3613\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.5458 - loss: 1.2739 - val_accuracy: 0.6092 - val_loss: 1.1258\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - accuracy: 0.6201 - loss: 1.0798 - val_accuracy: 0.6382 - val_loss: 1.0367\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - accuracy: 0.6680 - loss: 0.9593 - val_accuracy: 0.6520 - val_loss: 1.0038\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.6981 - loss: 0.8668 - val_accuracy: 0.6837 - val_loss: 0.9203\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# ✅ Reload CIFAR-10 dataset (Fix missing variables)\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()  # ✅ Reload dataset\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # ✅ Normalize images\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()  # ✅ Flatten labels\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "# ✅ Define CNN Model Again\n",
    "def create_cnn():\n",
    "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Flatten()(x)  # Feature extraction layer\n",
    "    x = layers.Dense(128, activation='relu', name=\"feature_layer\")(x)  # ✅ Feature Layer\n",
    "    outputs = layers.Dense(10, activation='softmax')(x)  # ✅ Output Layer\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ✅ Train CNN Model Again\n",
    "cnn_model = create_cnn()\n",
    "cnn_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)  # ✅ Train CNN\n",
    "# ✅ Extract Features using the trained CNN\n",
    "feature_extractor = models.Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(\"feature_layer\").output)\n",
    "\n",
    "# ✅ Get extracted features for both training and test sets\n",
    "train_features = feature_extractor.predict(x_train, batch_size=64)\n",
    "test_features = feature_extractor.predict(x_test, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27399fbe-6134-42f5-b1bd-95175f6489aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 44ms/step - accuracy: 0.3072 - loss: 1.8606 - val_accuracy: 0.5023 - val_loss: 1.3863\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.5363 - loss: 1.2868 - val_accuracy: 0.5903 - val_loss: 1.1733\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - accuracy: 0.6066 - loss: 1.1163 - val_accuracy: 0.6266 - val_loss: 1.0747\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 41ms/step - accuracy: 0.6488 - loss: 0.9981 - val_accuracy: 0.6472 - val_loss: 1.0091\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.6837 - loss: 0.9088 - val_accuracy: 0.6497 - val_loss: 1.0166\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step\n",
      "Random Forest Classification Accuracy: 0.6814\n",
      "Feature extractor model summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ feature_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_13 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_14 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ feature_layer (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m65,664\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">158,912</span> (620.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m158,912\u001b[0m (620.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">158,912</span> (620.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m158,912\u001b[0m (620.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_features: (50000, 128)\n",
      "Shape of test_features: (10000, 128)\n",
      "Shape of y_train: (50000,)\n",
      "Shape of y_test: (10000,)\n",
      "First 5 Predictions: [3 8 8 0 6]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# ✅ Reload CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize images\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()  # Flatten labels\n",
    "\n",
    "# ✅ Rebuild the trained CNN\n",
    "def create_cnn():\n",
    "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)  # Feature extraction layer\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name=\"feature_layer\")(x)  # ✅ Feature Layer\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(x)  # ✅ Output Layer\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ✅ Train the CNN Model Again\n",
    "cnn_model = create_cnn()\n",
    "cnn_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# ✅ Extract Features using the trained CNN\n",
    "feature_extractor = models.Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(\"feature_layer\").output)\n",
    "\n",
    "# ✅ Get extracted features for both training and test sets\n",
    "train_features = feature_extractor.predict(x_train, batch_size=64)\n",
    "test_features = feature_extractor.predict(x_test, batch_size=64)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ✅ Normalize extracted features\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# ✅ Ensure Random Forest is trained properly\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(train_features, y_train)  # 🔥 Train the classifier again\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ✅ Make Predictions\n",
    "y_pred = classifier.predict(test_features)\n",
    "\n",
    "# ✅ Compute Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# ✅ Print Accuracy\n",
    "print(f'Random Forest Classification Accuracy: {accuracy:.4f}')\n",
    "print(\"Feature extractor model summary:\")\n",
    "feature_extractor.summary()\n",
    "\n",
    "print(\"Shape of train_features:\", train_features.shape)  # Should be (50000, N)\n",
    "print(\"Shape of test_features:\", test_features.shape)    # Should be (10000, N)\n",
    "print(\"Shape of y_train:\", y_train.shape)                # Should be (50000,)\n",
    "print(\"Shape of y_test:\", y_test.shape)                  # Should be (10000,)\n",
    "print(\"First 5 Predictions:\", y_pred[:5])                # Should print sample predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b90e06-4ce9-4a16-862a-ec4911ae3a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Accuracy: 0.6569\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Try k-NN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(train_features, y_train)\n",
    "y_knn_pred = knn.predict(test_features)\n",
    "print(f'k-NN Accuracy: {accuracy_score(y_test, y_knn_pred):.4f}')\n",
    "\n",
    "# Try SVM\n",
    "svm = SVC()\n",
    "svm.fit(train_features, y_train)\n",
    "y_svm_pred = svm.predict(test_features)\n",
    "print(f'SVM Accuracy: {accuracy_score(y_test, y_svm_pred):.4f}')\n",
    "\n",
    "# Try Decision Tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(train_features, y_train)\n",
    "y_dt_pred = dt.predict(test_features)\n",
    "print(f'Decision Tree Accuracy: {accuracy_score(y_test, y_dt_pred):.4f}')\n",
    "\n",
    "# Try Naïve Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(train_features, y_train)\n",
    "y_nb_pred = nb.predict(test_features)\n",
    "print(f'Naïve Bayes Accuracy: {accuracy_score(y_test, y_nb_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cf5d32a-044e-4b94-86a1-45a614410f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 44ms/step - accuracy: 0.3188 - loss: 1.8423 - val_accuracy: 0.4673 - val_loss: 1.4752\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 41ms/step - accuracy: 0.5402 - loss: 1.2887 - val_accuracy: 0.5905 - val_loss: 1.1401\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.6140 - loss: 1.0935 - val_accuracy: 0.6402 - val_loss: 1.0321\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.6582 - loss: 0.9718 - val_accuracy: 0.6543 - val_loss: 0.9797\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.6913 - loss: 0.8839 - val_accuracy: 0.6661 - val_loss: 0.9531\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# ✅ Reload CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize images\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()  # Flatten labels\n",
    "\n",
    "# ✅ Rebuild the trained CNN\n",
    "def create_cnn():\n",
    "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)  # Feature extraction layer\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name=\"feature_layer\")(x)  # ✅ Feature Layer\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(x)  # ✅ Output Layer\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ✅ Train the CNN Model Again\n",
    "cnn_model = create_cnn()\n",
    "cnn_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# ✅ Extract Features using the trained CNN\n",
    "feature_extractor = models.Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(\"feature_layer\").output)\n",
    "\n",
    "# ✅ Get extracted features for both training and test sets\n",
    "train_features = feature_extractor.predict(x_train, batch_size=64)\n",
    "test_features = feature_extractor.predict(x_test, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0950bc9d-f37f-4fbd-8824-9327286d8865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ✅ Normalize extracted features\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "# ✅ Convert labels for regression\n",
    "y_train_reg = y_train.astype(float)\n",
    "y_test_reg = y_test.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a7cf5d-6c6f-4dd7-8d3d-ad40bb084b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MAE: 1.8141\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# ✅ Try Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(train_features, y_train_reg)\n",
    "y_lr_pred = lr.predict(test_features)\n",
    "print(f'Linear Regression MAE: {mean_absolute_error(y_test_reg, y_lr_pred):.4f}')\n",
    "\n",
    "# ✅ Try SVR\n",
    "svr = SVR()\n",
    "svr.fit(train_features, y_train_reg)\n",
    "y_svr_pred = svr.predict(test_features)\n",
    "print(f'SVR MAE: {mean_absolute_error(y_test_reg, y_svr_pred):.4f}')\n",
    "\n",
    "# ✅ Try Gradient Boosting\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(train_features, y_train_reg)\n",
    "y_gbr_pred = gbr.predict(test_features)\n",
    "print(f'Gradient Boosting MAE: {mean_absolute_error(y_test_reg, y_gbr_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a7af9e3-b9f4-4fcf-8cdc-071e348c572a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 45ms/step - accuracy: 0.3291 - loss: 1.8162 - val_accuracy: 0.5110 - val_loss: 1.3513\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.5568 - loss: 1.2412 - val_accuracy: 0.6085 - val_loss: 1.1126\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.6274 - loss: 1.0610 - val_accuracy: 0.6542 - val_loss: 0.9983\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 44ms/step - accuracy: 0.6739 - loss: 0.9371 - val_accuracy: 0.6624 - val_loss: 0.9778\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.7020 - loss: 0.8473 - val_accuracy: 0.6874 - val_loss: 0.9083\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# ✅ Reload CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize images\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()  # Flatten labels\n",
    "\n",
    "# ✅ Rebuild the trained CNN\n",
    "def create_cnn():\n",
    "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)  # Feature extraction layer\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name=\"feature_layer\")(x)  # ✅ Feature Layer\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(x)  # ✅ Output Layer\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ✅ Train the CNN Model Again\n",
    "cnn_model = create_cnn()\n",
    "cnn_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# ✅ Extract Features using the trained CNN\n",
    "feature_extractor = models.Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(\"feature_layer\").output)\n",
    "\n",
    "# ✅ Get extracted features for both training and test sets\n",
    "train_features = feature_extractor.predict(x_train, batch_size=64)\n",
    "test_features = feature_extractor.predict(x_test, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20b100dc-fcda-4b5e-8620-396e8da8f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ✅ Normalize extracted features\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "test_features = scaler.transform(test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a87410dc-4773-4a33-af30-e55739ba403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Convert labels for regression\n",
    "y_train_reg = y_train.astype(float)\n",
    "y_test_reg = y_test.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b56e975-3f40-4ec3-bbcf-1bbb999fbd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost MAE: 1.3998\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# ✅ Train XGBoost\n",
    "xgb = XGBRegressor()\n",
    "xgb.fit(train_features, y_train_reg)\n",
    "\n",
    "# ✅ Make Predictions\n",
    "y_xgb_pred = xgb.predict(test_features)\n",
    "\n",
    "# ✅ Compute MAE\n",
    "print(f'XGBoost MAE: {mean_absolute_error(y_test_reg, y_xgb_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28bffaca-3718-42a9-9f18-fb008d2a02f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost MAE (Tuned): 1.3536\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(n_estimators=200, learning_rate=0.1, max_depth=6)\n",
    "xgb.fit(train_features, y_train_reg)\n",
    "y_xgb_pred = xgb.predict(test_features)\n",
    "print(f'XGBoost MAE (Tuned): {mean_absolute_error(y_test_reg, y_xgb_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "291e7a4a-9e9f-42e7-97de-ca804b17f57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 42ms/step - accuracy: 0.3233 - loss: 1.8129 - val_accuracy: 0.5304 - val_loss: 1.3216\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 42ms/step - accuracy: 0.5619 - loss: 1.2446 - val_accuracy: 0.5884 - val_loss: 1.1760\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 44ms/step - accuracy: 0.6283 - loss: 1.0603 - val_accuracy: 0.6336 - val_loss: 1.0550\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.6706 - loss: 0.9475 - val_accuracy: 0.6680 - val_loss: 0.9535\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.7092 - loss: 0.8444 - val_accuracy: 0.6652 - val_loss: 0.9645\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# ✅ Reload CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize images\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()  # Flatten labels\n",
    "\n",
    "# ✅ Rebuild the trained CNN\n",
    "def create_cnn():\n",
    "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)  # Feature extraction layer\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name=\"feature_layer\")(x)  # ✅ Feature Layer\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(x)  # ✅ Output Layer\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ✅ Train the CNN Model Again\n",
    "cnn_model = create_cnn()\n",
    "cnn_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# ✅ Extract Features using the trained CNN\n",
    "feature_extractor = models.Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(\"feature_layer\").output)\n",
    "\n",
    "# ✅ Get extracted features for both training and test sets\n",
    "train_features = feature_extractor.predict(x_train, batch_size=64)\n",
    "test_features = feature_extractor.predict(x_test, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "765fa428-38d0-4e23-978a-526a7bc5f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ✅ Normalize extracted features\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "test_features = scaler.transform(test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d431330-d230-4297-b352-a49c03816ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔴 Error: train_features is missing! Run feature extraction first.\n"
     ]
    }
   ],
   "source": [
    "if 'train_features' not in locals():\n",
    "    print(\"🔴 Error: train_features is missing! Run feature extraction first.\")\n",
    "else:\n",
    "    print(\"✅ train_features is available!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5674ed68-2e58-4df0-a516-d1f1b759abc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 44ms/step - accuracy: 0.3131 - loss: 1.8427 - val_accuracy: 0.5167 - val_loss: 1.3494\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.5439 - loss: 1.2757 - val_accuracy: 0.5986 - val_loss: 1.1562\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 44ms/step - accuracy: 0.6104 - loss: 1.0954 - val_accuracy: 0.6272 - val_loss: 1.0790\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.6595 - loss: 0.9769 - val_accuracy: 0.6622 - val_loss: 0.9810\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step - accuracy: 0.6970 - loss: 0.8757 - val_accuracy: 0.6800 - val_loss: 0.9232\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step\n",
      "✅ Feature extraction completed!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# ✅ Reload CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize images\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()  # Flatten labels\n",
    "\n",
    "# ✅ Rebuild the trained CNN\n",
    "def create_cnn():\n",
    "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)  # Feature extraction layer\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name=\"feature_layer\")(x)  # ✅ Feature Layer\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(x)  # ✅ Output Layer\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ✅ Train the CNN Model Again\n",
    "cnn_model = create_cnn()\n",
    "cnn_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# ✅ Extract Features using the trained CNN\n",
    "feature_extractor = models.Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(\"feature_layer\").output)\n",
    "\n",
    "# ✅ Get extracted features for both training and test sets\n",
    "train_features = feature_extractor.predict(x_train, batch_size=64)\n",
    "test_features = feature_extractor.predict(x_test, batch_size=64)\n",
    "\n",
    "print(\"✅ Feature extraction completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc239cbf-7521-4211-9b45-b016042c3670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature normalization completed!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ✅ Normalize extracted features\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "print(\"✅ Feature normalization completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95fcaebb-d585-4629-8ec1-f99f664a2837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Labels converted for regression!\n"
     ]
    }
   ],
   "source": [
    "# ✅ Convert labels for regression\n",
    "y_train_reg = y_train.astype(float)\n",
    "y_test_reg = y_test.astype(float)\n",
    "\n",
    "print(\"✅ Labels converted for regression!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7443bc23-b7e9-41a1-b200-26c4aadcbb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔴 Error: train_features is missing! Run feature extraction first.\n"
     ]
    }
   ],
   "source": [
    "if 'train_features' not in locals():\n",
    "    print(\"🔴 Error: train_features is missing! Run feature extraction first.\")\n",
    "else:\n",
    "    print(\"✅ train_features is available!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a63a63-11c0-438f-bc62-15bc97c39774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# ✅ Reload CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize images\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()  # Flatten labels\n",
    "\n",
    "# ✅ Rebuild the trained CNN\n",
    "def create_cnn():\n",
    "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)  # Feature extraction layer\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name=\"feature_layer\")(x)  # ✅ Feature Layer\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(x)  # ✅ Output Layer\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ✅ Train the CNN Model Again\n",
    "cnn_model = create_cnn()\n",
    "cnn_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# ✅ Extract Features using the trained CNN\n",
    "feature_extractor = models.Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(\"feature_layer\").output)\n",
    "\n",
    "# ✅ Get extracted features for both training and test sets\n",
    "train_features = feature_extractor.predict(x_train, batch_size=64)\n",
    "test_features = feature_extractor.predict(x_test, batch_size=64)\n",
    "\n",
    "print(\"✅ Feature extraction completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6356b54e-eda0-408e-8e93-caec86428fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if 'train_features' exists...\n",
      "❌ 'train_features' is MISSING! You need to re-run feature extraction.\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking if 'train_features' exists...\")\n",
    "\n",
    "if 'train_features' in globals():\n",
    "    print(\"✅ 'train_features' is available!\")\n",
    "else:\n",
    "    print(\"❌ 'train_features' is MISSING! You need to re-run feature extraction.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9724ff3-0044-4fd5-9d36-f003a4946bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 45ms/step - accuracy: 0.3113 - loss: 1.8431 - val_accuracy: 0.5175 - val_loss: 1.3463\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.5397 - loss: 1.2861 - val_accuracy: 0.5862 - val_loss: 1.1666\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.6023 - loss: 1.1135 - val_accuracy: 0.6047 - val_loss: 1.1219\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.6429 - loss: 1.0173 - val_accuracy: 0.6306 - val_loss: 1.0508\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.6766 - loss: 0.9205 - val_accuracy: 0.6587 - val_loss: 0.9926\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step\n",
      "✅ Feature extraction completed!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# ✅ Reload CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize images\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()  # Flatten labels\n",
    "\n",
    "# ✅ Rebuild the trained CNN\n",
    "def create_cnn():\n",
    "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)  # Feature extraction layer\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name=\"feature_layer\")(x)  # ✅ Feature Layer\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(x)  # ✅ Output Layer\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ✅ Train the CNN Model Again\n",
    "cnn_model = create_cnn()\n",
    "cnn_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# ✅ Extract Features using the trained CNN\n",
    "feature_extractor = models.Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(\"feature_layer\").output)\n",
    "\n",
    "# ✅ Get extracted features for both training and test sets\n",
    "train_features = feature_extractor.predict(x_train, batch_size=64)\n",
    "test_features = feature_extractor.predict(x_test, batch_size=64)\n",
    "\n",
    "print(\"✅ Feature extraction completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "194f3345-ab6f-4fd6-8034-9909d9205d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature normalization completed!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ✅ Normalize extracted features\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "print(\"✅ Feature normalization completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d5e3aaa-f075-4b02-b2d6-25ce9650b04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Labels converted for regression!\n"
     ]
    }
   ],
   "source": [
    "# ✅ Convert labels for regression\n",
    "y_train_reg = y_train.astype(float)\n",
    "y_test_reg = y_test.astype(float)\n",
    "\n",
    "print(\"✅ Labels converted for regression!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c592d3c-7d65-4637-8e2a-286d25297a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# ✅ Train Gradient Boosting\n",
    "gbr = GradientBoostingRegressor(n_estimators=200)\n",
    "gbr.fit(train_features, y_train_reg)\n",
    "\n",
    "# ✅ Make Predictions\n",
    "y_gbr_pred = gbr.predict(test_features)\n",
    "\n",
    "# ✅ Compute MAE\n",
    "print(f'Gradient Boosting MAE: {mean_absolute_error(y_test_reg, y_gbr_pred):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d1bb50-93a0-4967-9cc9-f8b6a02802e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking Variables...\")\n",
    "\n",
    "print(f\"train_features exists: {'train_features' in globals()}\")\n",
    "print(f\"test_features exists: {'test_features' in globals()}\")\n",
    "print(f\"y_train_reg exists: {'y_train_reg' in globals()}\")\n",
    "print(f\"y_test_reg exists: {'y_test_reg' in globals()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e22aa53-5157-4cd5-8543-7c3dcf7d599b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Variables...\n",
      "train_features exists: False\n",
      "test_features exists: False\n",
      "y_train_reg exists: False\n",
      "y_test_reg exists: False\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking Variables...\")\n",
    "\n",
    "print(f\"train_features exists: {'train_features' in globals()}\")\n",
    "print(f\"test_features exists: {'test_features' in globals()}\")\n",
    "print(f\"y_train_reg exists: {'y_train_reg' in globals()}\")\n",
    "print(f\"y_test_reg exists: {'y_test_reg' in globals()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c1e223f-fc79-4ab8-9642-41946a831952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 43ms/step - accuracy: 0.3188 - loss: 1.8226 - val_accuracy: 0.4927 - val_loss: 1.4120\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.5398 - loss: 1.2764 - val_accuracy: 0.5841 - val_loss: 1.1786\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.6065 - loss: 1.1041 - val_accuracy: 0.6363 - val_loss: 1.0395\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 42ms/step - accuracy: 0.6611 - loss: 0.9673 - val_accuracy: 0.6457 - val_loss: 1.0407\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.6899 - loss: 0.8931 - val_accuracy: 0.6800 - val_loss: 0.9206\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step\n",
      "✅ Feature extraction completed!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# ✅ Reload CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize images\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()  # Flatten labels\n",
    "\n",
    "# ✅ Rebuild the trained CNN\n",
    "def create_cnn():\n",
    "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)  # Feature extraction layer\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name=\"feature_layer\")(x)  # ✅ Feature Layer\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(x)  # ✅ Output Layer\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ✅ Train the CNN Model Again\n",
    "cnn_model = create_cnn()\n",
    "cnn_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# ✅ Extract Features using the trained CNN\n",
    "feature_extractor = models.Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(\"feature_layer\").output)\n",
    "\n",
    "# ✅ Get extracted features for both training and test sets\n",
    "train_features = feature_extractor.predict(x_train, batch_size=64)\n",
    "test_features = feature_extractor.predict(x_test, batch_size=64)\n",
    "\n",
    "print(\"✅ Feature extraction completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae6a18bd-245b-4354-bbb1-3545edc9334e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checking Variables...\n",
      "train_features exists: True\n",
      "test_features exists: True\n",
      "y_train_reg exists: False\n",
      "y_test_reg exists: False\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 Checking Variables...\")\n",
    "\n",
    "print(f\"train_features exists: {'train_features' in globals()}\")\n",
    "print(f\"test_features exists: {'test_features' in globals()}\")\n",
    "print(f\"y_train_reg exists: {'y_train_reg' in globals()}\")\n",
    "print(f\"y_test_reg exists: {'y_test_reg' in globals()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2ed28c1-a487-45dd-bd67-68a0f7696322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Labels converted for regression!\n"
     ]
    }
   ],
   "source": [
    "# ✅ Convert classification labels into numeric regression values\n",
    "y_train_reg = y_train.astype(float)\n",
    "y_test_reg = y_test.astype(float)\n",
    "\n",
    "print(\"✅ Labels converted for regression!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56578d97-0501-44a2-9149-7431ad1d19bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_reg exists: True\n",
      "y_test_reg exists: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_train_reg exists: {'y_train_reg' in globals()}\")\n",
    "print(f\"y_test_reg exists: {'y_test_reg' in globals()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d650e711-d9a0-4a44-8aec-4a3c89e5f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# ✅ Train Gradient Boosting\n",
    "gbr = GradientBoostingRegressor(n_estimators=200, random_state=42)\n",
    "gbr.fit(train_features, y_train_reg)\n",
    "\n",
    "# ✅ Make Predictions\n",
    "y_gbr_pred = gbr.predict(test_features)\n",
    "\n",
    "# ✅ Compute MAE\n",
    "print(f'Gradient Boosting MAE: {mean_absolute_error(y_test_reg, y_gbr_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4cc11-4abc-4018-882a-baab4ad669d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# ✅ Debugging Check\n",
    "print(f\"Checking train_features shape: {train_features.shape}\")\n",
    "print(f\"Checking test_features shape: {test_features.shape}\")\n",
    "print(f\"Checking y_train_reg shape: {y_train_reg.shape}\")\n",
    "print(f\"Checking y_test_reg shape: {y_test_reg.shape}\")\n",
    "\n",
    "# ✅ Train Gradient Boosting\n",
    "try:\n",
    "    gbr = GradientBoostingRegressor(n_estimators=200, random_state=42)\n",
    "    gbr.fit(train_features, y_train_reg)\n",
    "    \n",
    "    # ✅ Make Predictions\n",
    "    y_gbr_pred = gbr.predict(test_features)\n",
    "    \n",
    "    # ✅ Compute MAE\n",
    "    print(f'Gradient Boosting MAE: {mean_absolute_error(y_test_reg, y_gbr_pred):.4f}')\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error while training Gradient Boosting: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20508dd0-41e4-47fb-b9b0-f7122c2323fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Variables...\n",
      "train_features exists: False\n",
      "test_features exists: False\n",
      "y_train_reg exists: False\n",
      "y_test_reg exists: False\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking Variables...\")\n",
    "\n",
    "print(f\"train_features exists: {'train_features' in globals()}\")\n",
    "print(f\"test_features exists: {'test_features' in globals()}\")\n",
    "print(f\"y_train_reg exists: {'y_train_reg' in globals()}\")\n",
    "print(f\"y_test_reg exists: {'y_test_reg' in globals()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87d2fd31-fadf-42c4-bfa2-73f38d10962b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - accuracy: 0.3076 - loss: 1.8563 - val_accuracy: 0.4925 - val_loss: 1.4199\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.5357 - loss: 1.3008 - val_accuracy: 0.5831 - val_loss: 1.1849\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.6037 - loss: 1.1178 - val_accuracy: 0.6194 - val_loss: 1.0875\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.6597 - loss: 0.9809 - val_accuracy: 0.6418 - val_loss: 1.0360\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 34ms/step - accuracy: 0.6849 - loss: 0.9008 - val_accuracy: 0.6626 - val_loss: 0.9742\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step\n",
      "✅ Feature extraction completed!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# ✅ Reload CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize images\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()  # Flatten labels\n",
    "\n",
    "# ✅ Rebuild the trained CNN\n",
    "def create_cnn():\n",
    "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)  # Feature extraction layer\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name=\"feature_layer\")(x)  # ✅ Feature Layer\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(x)  # ✅ Output Layer\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ✅ Train the CNN Model Again\n",
    "cnn_model = create_cnn()\n",
    "cnn_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# ✅ Extract Features using the trained CNN\n",
    "feature_extractor = models.Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(\"feature_layer\").output)\n",
    "\n",
    "# ✅ Get extracted features for both training and test sets\n",
    "train_features = feature_extractor.predict(x_train, batch_size=64)\n",
    "test_features = feature_extractor.predict(x_test, batch_size=64)\n",
    "\n",
    "print(\"✅ Feature extraction completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea95bcc6-7c7c-4e44-965c-e9164d2d08ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Variables Again...\n",
      "train_features exists: True\n",
      "test_features exists: True\n",
      "y_train exists: True\n",
      "y_test exists: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking Variables Again...\")\n",
    "\n",
    "print(f\"train_features exists: {'train_features' in globals()}\")\n",
    "print(f\"test_features exists: {'test_features' in globals()}\")\n",
    "print(f\"y_train exists: {'y_train' in globals()}\")\n",
    "print(f\"y_test exists: {'y_test' in globals()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1ca47ad-a3a1-4104-a89b-784d5b8f3400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature normalization completed!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ✅ Normalize extracted features\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "print(\"✅ Feature normalization completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2b57a63-b50e-46d0-bb9d-057561ff9a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SWAGA\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_train_reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m\n\u001b[0;32m      5\u001b[0m ann \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m      6\u001b[0m     Dense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(train_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],)),\n\u001b[0;32m      7\u001b[0m     Dense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      8\u001b[0m     Dense(\u001b[38;5;241m32\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      9\u001b[0m     Dense(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Single output neuron for regression\u001b[39;00m\n\u001b[0;32m     10\u001b[0m ])\n\u001b[0;32m     12\u001b[0m ann\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_absolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m ann\u001b[38;5;241m.\u001b[39mfit(train_features, \u001b[43my_train_reg\u001b[49m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# ✅ Make Predictions\u001b[39;00m\n\u001b[0;32m     16\u001b[0m y_ann_pred \u001b[38;5;241m=\u001b[39m ann\u001b[38;5;241m.\u001b[39mpredict(test_features)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train_reg' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# ✅ Build a Neural Network (ANN)\n",
    "ann = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(train_features.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Single output neuron for regression\n",
    "])\n",
    "\n",
    "ann.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "ann.fit(train_features, y_train_reg, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ✅ Make Predictions\n",
    "y_ann_pred = ann.predict(test_features)\n",
    "\n",
    "# ✅ Compute MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(f'ANN Regression MAE: {mean_absolute_error(y_test_reg, y_ann_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25193c04-c786-40a5-8da5-505825bd019b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Variables...\n",
      "train_features exists: True\n",
      "test_features exists: True\n",
      "y_train_reg exists: False\n",
      "y_test_reg exists: False\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking Variables...\")\n",
    "\n",
    "print(f\"train_features exists: {'train_features' in globals()}\")\n",
    "print(f\"test_features exists: {'test_features' in globals()}\")\n",
    "print(f\"y_train_reg exists: {'y_train_reg' in globals()}\")\n",
    "print(f\"y_test_reg exists: {'y_test_reg' in globals()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af5fca70-ba7f-461e-9c67-affb6709b881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Labels converted for regression!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ✅ Convert classification labels into numeric regression values\n",
    "y_train_reg = np.array(y_train).astype(np.float32)\n",
    "y_test_reg = np.array(y_test).astype(np.float32)\n",
    "\n",
    "print(\"✅ Labels converted for regression!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b168c76f-e16a-4db6-895f-6d93ee9902c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_reg exists: True\n",
      "y_test_reg exists: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_train_reg exists: {'y_train_reg' in globals()}\")\n",
    "print(f\"y_test_reg exists: {'y_test_reg' in globals()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b54defc-063b-47b4-9745-4a3415d33773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.6111 - val_loss: 1.3334\n",
      "Epoch 2/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.1797 - val_loss: 1.2657\n",
      "Epoch 3/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.0953 - val_loss: 1.2554\n",
      "Epoch 4/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.0338 - val_loss: 1.1959\n",
      "Epoch 5/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.0076 - val_loss: 1.1808\n",
      "Epoch 6/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.9883 - val_loss: 1.1865\n",
      "Epoch 7/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.9593 - val_loss: 1.1750\n",
      "Epoch 8/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.9320 - val_loss: 1.1314\n",
      "Epoch 9/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.9082 - val_loss: 1.1561\n",
      "Epoch 10/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.9002 - val_loss: 1.1470\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "ANN Regression MAE: 1.1377\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# ✅ Build a Neural Network (ANN)\n",
    "ann = Sequential([\n",
    "    Input(shape=(train_features.shape[1],)),  # ✅ Correct input format\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Single output neuron for regression\n",
    "])\n",
    "\n",
    "ann.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "ann.fit(train_features, y_train_reg, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ✅ Make Predictions\n",
    "y_ann_pred = ann.predict(test_features)\n",
    "\n",
    "# ✅ Compute MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(f'ANN Regression MAE: {mean_absolute_error(y_test_reg, y_ann_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6d0c015-0bcf-42f0-abc2-48f0a0d75ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SWAGA\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 1.5416 - val_loss: 1.3016\n",
      "Epoch 2/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.1555 - val_loss: 1.2972\n",
      "Epoch 3/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.0690 - val_loss: 1.1955\n",
      "Epoch 4/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.9877 - val_loss: 1.1750\n",
      "Epoch 5/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.9745 - val_loss: 1.2016\n",
      "Epoch 6/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.9457 - val_loss: 1.1348\n",
      "Epoch 7/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.9347 - val_loss: 1.1363\n",
      "Epoch 8/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.9020 - val_loss: 1.1265\n",
      "Epoch 9/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.8924 - val_loss: 1.0985\n",
      "Epoch 10/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.8726 - val_loss: 1.1214\n",
      "Epoch 11/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.8522 - val_loss: 1.1177\n",
      "Epoch 12/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.8397 - val_loss: 1.0851\n",
      "Epoch 13/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.8413 - val_loss: 1.0888\n",
      "Epoch 14/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.8238 - val_loss: 1.1060\n",
      "Epoch 15/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.7984 - val_loss: 1.0764\n",
      "Epoch 16/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.7910 - val_loss: 1.0834\n",
      "Epoch 17/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.8043 - val_loss: 1.0861\n",
      "Epoch 18/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.7757 - val_loss: 1.0665\n",
      "Epoch 19/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.7742 - val_loss: 1.0784\n",
      "Epoch 20/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.7668 - val_loss: 1.0840\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Improved ANN Regression MAE: 1.0862\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "# ✅ Build an Improved Neural Network\n",
    "ann_improved = Sequential([\n",
    "    Input(shape=(train_features.shape[1],)),\n",
    "    Dense(256, activation='relu'),  # More neurons\n",
    "    Dense(128, activation=LeakyReLU(alpha=0.1)),  # LeakyReLU for better learning\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Regression output\n",
    "])\n",
    "\n",
    "ann_improved.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "ann_improved.fit(train_features, y_train_reg, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ✅ Make Predictions\n",
    "y_ann_improved_pred = ann_improved.predict(test_features)\n",
    "\n",
    "# ✅ Compute MAE\n",
    "print(f'Improved ANN Regression MAE: {mean_absolute_error(y_test_reg, y_ann_improved_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2941811-ec1f-43ee-b44e-ea6f6d88b798",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: 1.6709 - val_loss: 1.3826\n",
      "Epoch 2/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 1.2723 - val_loss: 1.4005\n",
      "Epoch 3/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.1853 - val_loss: 1.2235\n",
      "Epoch 4/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 1.0695 - val_loss: 1.2085\n",
      "Epoch 5/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.0109 - val_loss: 1.1674\n",
      "Epoch 6/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.9760 - val_loss: 1.1318\n",
      "Epoch 7/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9581 - val_loss: 1.1174\n",
      "Epoch 8/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9456 - val_loss: 1.1036\n",
      "Epoch 9/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.9287 - val_loss: 1.0998\n",
      "Epoch 10/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9116 - val_loss: 1.1006\n",
      "Epoch 11/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9004 - val_loss: 1.0991\n",
      "Epoch 12/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.8984 - val_loss: 1.0881\n",
      "Epoch 13/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.9042 - val_loss: 1.0955\n",
      "Epoch 14/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.8928 - val_loss: 1.0860\n",
      "Epoch 15/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.8854 - val_loss: 1.0661\n",
      "Epoch 16/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.8883 - val_loss: 1.0768\n",
      "Epoch 17/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.8532 - val_loss: 1.0902\n",
      "Epoch 18/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.8488 - val_loss: 1.1238\n",
      "Epoch 19/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.8659 - val_loss: 1.0889\n",
      "Epoch 20/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.8665 - val_loss: 1.0956\n",
      "Epoch 21/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.8683 - val_loss: 1.0859\n",
      "Epoch 22/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.8417 - val_loss: 1.0808\n",
      "Epoch 23/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.8547 - val_loss: 1.0844\n",
      "Epoch 24/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.8500 - val_loss: 1.1214\n",
      "Epoch 25/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.8465 - val_loss: 1.0814\n",
      "Epoch 26/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.8467 - val_loss: 1.1015\n",
      "Epoch 27/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.8482 - val_loss: 1.0897\n",
      "Epoch 28/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.8361 - val_loss: 1.1034\n",
      "Epoch 29/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.8322 - val_loss: 1.1019\n",
      "Epoch 30/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.8344 - val_loss: 1.0924\n",
      "Epoch 31/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.8266 - val_loss: 1.1027\n",
      "Epoch 32/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.8127 - val_loss: 1.0807\n",
      "Epoch 33/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.8317 - val_loss: 1.0675\n",
      "Epoch 34/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.8325 - val_loss: 1.0740\n",
      "Epoch 35/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 0.8158 - val_loss: 1.0643\n",
      "Epoch 36/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.8220 - val_loss: 1.0899\n",
      "Epoch 37/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.8145 - val_loss: 1.0714\n",
      "Epoch 38/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.7988 - val_loss: 1.0909\n",
      "Epoch 39/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.8033 - val_loss: 1.0863\n",
      "Epoch 40/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.8021 - val_loss: 1.0911\n",
      "Epoch 41/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.8077 - val_loss: 1.1100\n",
      "Epoch 42/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.8048 - val_loss: 1.0763\n",
      "Epoch 43/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.7972 - val_loss: 1.0638\n",
      "Epoch 44/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.7959 - val_loss: 1.0714\n",
      "Epoch 45/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.7916 - val_loss: 1.0693\n",
      "Epoch 46/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.7976 - val_loss: 1.0862\n",
      "Epoch 47/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.7824 - val_loss: 1.0681\n",
      "Epoch 48/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.7913 - val_loss: 1.0697\n",
      "Epoch 49/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.7743 - val_loss: 1.0750\n",
      "Epoch 50/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.7708 - val_loss: 1.0635\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Best ANN Regression MAE: 1.0742\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "\n",
    "# ✅ Build an Even Better ANN\n",
    "ann_best = Sequential([\n",
    "    Input(shape=(train_features.shape[1],)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.2),  # Prevent overfitting\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Regression output\n",
    "])\n",
    "\n",
    "ann_best.compile(optimizer=AdamW(learning_rate=0.001), loss='mean_absolute_error')\n",
    "ann_best.fit(train_features, y_train_reg, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ✅ Make Predictions\n",
    "y_ann_best_pred = ann_best.predict(test_features)\n",
    "\n",
    "# ✅ Compute MAE\n",
    "print(f'Best ANN Regression MAE: {mean_absolute_error(y_test_reg, y_ann_best_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ec5f063-ca03-4781-990c-0b6c0d94115b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Regression MAE: 1.4535\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# ✅ Train XGBoost\n",
    "xgb = XGBRegressor(n_estimators=200, random_state=42)\n",
    "xgb.fit(train_features, y_train_reg)\n",
    "\n",
    "# ✅ Make Predictions\n",
    "y_xgb_pred = xgb.predict(test_features)\n",
    "\n",
    "# ✅ Compute MAE\n",
    "print(f'XGBoost Regression MAE: {mean_absolute_error(y_test_reg, y_xgb_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca24be3-5bd3-4e2f-a90b-16ae27b5e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ✅ Train SVM\n",
    "svm = SVC()\n",
    "svm.fit(train_features, y_train)\n",
    "\n",
    "# ✅ Make Predictions\n",
    "y_svm_pred = svm.predict(test_features)\n",
    "\n",
    "# ✅ Compute Accuracy\n",
    "print(f'SVM Classification Accuracy: {accuracy_score(y_test, y_svm_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c19003-1106-4905-a3e6-7bcca4a48d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checking All Variables...\n",
      "train_features exists: True\n",
      "test_features exists: True\n",
      "y_train exists: True\n",
      "y_test exists: True\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 Checking All Variables...\")\n",
    "\n",
    "print(f\"train_features exists: {'train_features' in globals()}\")\n",
    "print(f\"test_features exists: {'test_features' in globals()}\")\n",
    "print(f\"y_train exists: {'y_train' in globals()}\")\n",
    "print(f\"y_test exists: {'y_test' in globals()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7240d27-8685-4ccb-aaf2-a13d7d7349d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a0764de-be11-428a-aaf5-d36a23572322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Labels converted to integer format!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ✅ Ensure labels are in integer format\n",
    "y_train = np.array(y_train).astype(int)\n",
    "y_test = np.array(y_test).astype(int)\n",
    "\n",
    "print(\"✅ Labels converted to integer format!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c2c356-0d6b-4b77-b3bc-63640dbf20b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ✅ Use a smaller dataset for SVM (to prevent crashes)\n",
    "subset_size = 2000\n",
    "train_subset = train_features[:subset_size]\n",
    "y_train_subset = y_train[:subset_size]\n",
    "\n",
    "# ✅ Train SVM\n",
    "print(\"Training SVM on smaller dataset...\")\n",
    "svm = SVC()\n",
    "svm.fit(train_subset, y_train_subset)\n",
    "\n",
    "# ✅ Make Predictions\n",
    "y_svm_pred = svm.predict(test_features)\n",
    "\n",
    "# ✅ Compute Accuracy\n",
    "print(f'SVM Classification Accuracy (Small Dataset): {accuracy_score(y_test, y_svm_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41693704-dd91-4013-bfc1-d9bcce2efb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training SVM on full dataset...\")\n",
    "\n",
    "try:\n",
    "    svm_full = SVC()\n",
    "    svm_full.fit(train_features, y_train)\n",
    "    \n",
    "    # ✅ Make Predictions\n",
    "    y_svm_pred_full = svm_full.predict(test_features)\n",
    "\n",
    "    # ✅ Compute Accuracy\n",
    "    print(f'SVM Classification Accuracy (Full Dataset): {accuracy_score(y_test, y_svm_pred_full):.4f}')\n",
    "except Exception as e:\n",
    "    print(f\"❌ SVM Training Failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1204b8c-0637-46cd-bf23-69c4fc36f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking Shapes and Data Types...\")\n",
    "\n",
    "print(f\"train_features shape: {train_features.shape}, dtype: {train_features.dtype}\")\n",
    "print(f\"test_features shape: {test_features.shape}, dtype: {test_features.dtype}\")\n",
    "print(f\"y_train shape: {y_train.shape}, dtype: {y_train.dtype}\")\n",
    "print(f\"y_test shape: {y_test.shape}, dtype: {y_test.dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f739d87a-b18b-4441-8866-762b1fe28fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔍 Debugging SVM Issue...\")\n",
    "\n",
    "# ✅ Check if train_features & test_features exist\n",
    "print(f\"train_features exists: {'train_features' in globals()}\")\n",
    "print(f\"test_features exists: {'test_features' in globals()}\")\n",
    "\n",
    "# ✅ Check if labels exist\n",
    "print(f\"y_train exists: {'y_train' in globals()}\")\n",
    "print(f\"y_test exists: {'y_test' in globals()}\")\n",
    "\n",
    "# ✅ Check the shape of each dataset\n",
    "print(f\"train_features shape: {train_features.shape}\")\n",
    "print(f\"test_features shape: {test_features.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# ✅ Check if labels are in correct format (must be integers)\n",
    "import numpy as np\n",
    "print(f\"y_train dtype: {y_train.dtype}, unique values: {np.unique(y_train)}\")\n",
    "print(f\"y_test dtype: {y_test.dtype}, unique values: {np.unique(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67e81419-2898-46df-beb7-ac25b9fcf432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Debugging k-NN Issue...\n",
      "train_features exists: False\n",
      "test_features exists: False\n",
      "y_train exists: False\n",
      "y_test exists: False\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_test exists: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_test\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mglobals\u001b[39m()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# ✅ Check the shape of each dataset\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_features shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtrain_features\u001b[49m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_features shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_features\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_features' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"🔍 Debugging k-NN Issue...\")\n",
    "\n",
    "# ✅ Check if train_features & test_features exist\n",
    "print(f\"train_features exists: {'train_features' in globals()}\")\n",
    "print(f\"test_features exists: {'test_features' in globals()}\")\n",
    "\n",
    "# ✅ Check if labels exist\n",
    "print(f\"y_train exists: {'y_train' in globals()}\")\n",
    "print(f\"y_test exists: {'y_test' in globals()}\")\n",
    "\n",
    "# ✅ Check the shape of each dataset\n",
    "print(f\"train_features shape: {train_features.shape}\")\n",
    "print(f\"test_features shape: {test_features.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# ✅ Check if labels are in correct format (must be integers)\n",
    "import numpy as np\n",
    "print(f\"y_train dtype: {y_train.dtype}, unique values: {np.unique(y_train)}\")\n",
    "print(f\"y_test dtype: {y_test.dtype}, unique values: {np.unique(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c53823d-c5e5-4e36-bb49-7f3d480635f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 63ms/step - accuracy: 0.3062 - loss: 1.8513 - val_accuracy: 0.5082 - val_loss: 1.3803\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 56ms/step - accuracy: 0.5481 - loss: 1.2698 - val_accuracy: 0.5946 - val_loss: 1.1522\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 53ms/step - accuracy: 0.6097 - loss: 1.1009 - val_accuracy: 0.6291 - val_loss: 1.0727\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 48ms/step - accuracy: 0.6571 - loss: 0.9771 - val_accuracy: 0.6540 - val_loss: 0.9930\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 50ms/step - accuracy: 0.6860 - loss: 0.8925 - val_accuracy: 0.6601 - val_loss: 0.9695\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step\n",
      "✅ Feature extraction completed!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# ✅ Reload CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize images\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()  # Flatten labels\n",
    "\n",
    "# ✅ Rebuild the trained CNN\n",
    "def create_cnn():\n",
    "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)  # Feature extraction layer\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name=\"feature_layer\")(x)  # ✅ Feature Layer\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(x)  # ✅ Output Layer\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ✅ Train the CNN Model Again\n",
    "cnn_model = create_cnn()\n",
    "cnn_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# ✅ Extract Features using the trained CNN\n",
    "feature_extractor = models.Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(\"feature_layer\").output)\n",
    "\n",
    "# ✅ Get extracted features for both training and test sets\n",
    "train_features = feature_extractor.predict(x_train, batch_size=64)\n",
    "test_features = feature_extractor.predict(x_test, batch_size=64)\n",
    "\n",
    "print(\"✅ Feature extraction completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e140639-4ab6-4a9c-8184-6c5d7573d4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checking Variables Again...\n",
      "train_features exists: True\n",
      "test_features exists: True\n",
      "y_train exists: True\n",
      "y_test exists: True\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 Checking Variables Again...\")\n",
    "\n",
    "print(f\"train_features exists: {'train_features' in globals()}\")  \n",
    "print(f\"test_features exists: {'test_features' in globals()}\")  \n",
    "print(f\"y_train exists: {'y_train' in globals()}\")  \n",
    "print(f\"y_test exists: {'y_test' in globals()}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eb0c642-4b44-49b6-8947-fc6ae8446502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature normalization completed!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ✅ Normalize extracted features\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "print(\"✅ Feature normalization completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70ed2df3-1bdf-419f-ae4c-fa5f7dc8f7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Classification Accuracy: 0.6561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ✅ Train k-NN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(train_features, y_train)\n",
    "\n",
    "# ✅ Make Predictions\n",
    "y_knn_pred = knn.predict(test_features)\n",
    "\n",
    "# ✅ Compute Accuracy\n",
    "print(f'k-NN Classification Accuracy: {accuracy_score(y_test, y_knn_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6783e0ca-f5b7-465b-8d5c-c4410b5efb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Accuracy: 0.6818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ✅ Train Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(train_features, y_train)\n",
    "\n",
    "# ✅ Make Predictions\n",
    "y_rf_pred = rf.predict(test_features)\n",
    "\n",
    "# ✅ Compute Accuracy\n",
    "print(f'Random Forest Classification Accuracy: {accuracy_score(y_test, y_rf_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d5c71f6-13d5-471d-abbb-088e2ed549f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Debugging Random Forest Issue...\n",
      "train_features exists: True\n",
      "test_features exists: True\n",
      "y_train exists: True\n",
      "y_test exists: True\n",
      "train_features shape: (50000, 128)\n",
      "test_features shape: (10000, 128)\n",
      "y_train shape: (50000,)\n",
      "y_test shape: (10000,)\n",
      "y_train dtype: uint8, unique values: [0 1 2 3 4 5 6 7 8 9]\n",
      "y_test dtype: uint8, unique values: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 Debugging Random Forest Issue...\")\n",
    "\n",
    "# ✅ Check if train_features & test_features exist\n",
    "print(f\"train_features exists: {'train_features' in globals()}\")\n",
    "print(f\"test_features exists: {'test_features' in globals()}\")\n",
    "\n",
    "# ✅ Check if labels exist\n",
    "print(f\"y_train exists: {'y_train' in globals()}\")\n",
    "print(f\"y_test exists: {'y_test' in globals()}\")\n",
    "\n",
    "# ✅ Check the shape of each dataset\n",
    "print(f\"train_features shape: {train_features.shape}\")\n",
    "print(f\"test_features shape: {test_features.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# ✅ Check if labels are in correct format (must be integers)\n",
    "import numpy as np\n",
    "print(f\"y_train dtype: {y_train.dtype}, unique values: {np.unique(y_train)}\")\n",
    "print(f\"y_test dtype: {y_test.dtype}, unique values: {np.unique(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d947aa36-82ca-4cb9-80b2-74abef66c842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest on a small dataset...\n",
      "Random Forest Classification Accuracy (Small Dataset): 0.6706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ✅ Use a smaller dataset for Random Forest\n",
    "subset_size = 10000\n",
    "train_subset = train_features[:subset_size]\n",
    "y_train_subset = y_train[:subset_size]\n",
    "\n",
    "# ✅ Train Random Forest\n",
    "print(\"Training Random Forest on a small dataset...\")\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(train_subset, y_train_subset)\n",
    "\n",
    "# ✅ Make Predictions\n",
    "y_rf_pred = rf.predict(test_features)\n",
    "\n",
    "# ✅ Compute Accuracy\n",
    "print(f'Random Forest Classification Accuracy (Small Dataset): {accuracy_score(y_test, y_rf_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72886d83-0c73-44cf-8daa-af6e2971291f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest on the full dataset...\n",
      "Random Forest Classification Accuracy (Full Dataset): 0.6818\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Training Random Forest on the full dataset...\")\n",
    "    rf_full = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_full.fit(train_features, y_train)\n",
    "    \n",
    "    # ✅ Make Predictions\n",
    "    y_rf_pred_full = rf_full.predict(test_features)\n",
    "\n",
    "    # ✅ Compute Accuracy\n",
    "    print(f'Random Forest Classification Accuracy (Full Dataset): {accuracy_score(y_test, y_rf_pred_full):.4f}')\n",
    "except Exception as e:\n",
    "    print(f\"❌ Random Forest Training Failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17221a3c-7a3d-4ef7-a7a2-8cf4f96406bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ✅ Train Naïve Bayes Classifier\n",
    "nb = GaussianNB()\n",
    "nb.fit(train_features, y_train)\n",
    "\n",
    "# ✅ Make Predictions\n",
    "y_nb_pred = nb.predict(test_features)\n",
    "\n",
    "# ✅ Compute Accuracy\n",
    "print(f'Naïve Bayes Classification Accuracy: {accuracy_score(y_test, y_nb_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c80e9298-2190-4ef8-8045-347ddaa3189f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 43ms/step - accuracy: 0.3229 - loss: 1.8302 - val_accuracy: 0.5106 - val_loss: 1.3753\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 42ms/step - accuracy: 0.5430 - loss: 1.2709 - val_accuracy: 0.5719 - val_loss: 1.2168\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.6165 - loss: 1.0946 - val_accuracy: 0.6334 - val_loss: 1.0445\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.6593 - loss: 0.9699 - val_accuracy: 0.6573 - val_loss: 0.9846\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step - accuracy: 0.6964 - loss: 0.8697 - val_accuracy: 0.6539 - val_loss: 1.0101\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step\n",
      "✅ Feature extraction completed!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# ✅ Reload CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize images\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()  # Flatten labels\n",
    "\n",
    "# ✅ Rebuild the trained CNN\n",
    "def create_cnn():\n",
    "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)  # Feature extraction layer\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name=\"feature_layer\")(x)  # ✅ Feature Layer\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(x)  # ✅ Output Layer\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ✅ Train the CNN Model Again\n",
    "cnn_model = create_cnn()\n",
    "cnn_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# ✅ Extract Features using the trained CNN\n",
    "feature_extractor = models.Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(\"feature_layer\").output)\n",
    "\n",
    "# ✅ Get extracted features for both training and test sets\n",
    "train_features = feature_extractor.predict(x_train, batch_size=64)\n",
    "test_features = feature_extractor.predict(x_test, batch_size=64)\n",
    "\n",
    "print(\"✅ Feature extraction completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b17d3d83-ca61-4ae4-b552-0ba05ca5b12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checking Variables Again...\n",
      "train_features exists: True\n",
      "test_features exists: True\n",
      "y_train exists: True\n",
      "y_test exists: True\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 Checking Variables Again...\")\n",
    "\n",
    "print(f\"train_features exists: {'train_features' in globals()}\")  \n",
    "print(f\"test_features exists: {'test_features' in globals()}\")  \n",
    "print(f\"y_train exists: {'y_train' in globals()}\")  \n",
    "print(f\"y_test exists: {'y_test' in globals()}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e18809c-593a-4426-934e-5dc688da3dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature scaling completed for Naïve Bayes!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ✅ Normalize extracted features\n",
    "scaler = MinMaxScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_features)\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "\n",
    "print(\"✅ Feature scaling completed for Naïve Bayes!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6273f810-c7c8-4b8f-896c-19938e1e1d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes Classification Accuracy: 0.5879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ✅ Train Naïve Bayes Classifier on Scaled Data\n",
    "nb = GaussianNB()\n",
    "nb.fit(train_features_scaled, y_train)\n",
    "\n",
    "# ✅ Make Predictions\n",
    "y_nb_pred = nb.predict(test_features_scaled)\n",
    "\n",
    "# ✅ Compute Accuracy\n",
    "print(f'Naïve Bayes Classification Accuracy: {accuracy_score(y_test, y_nb_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6db58d08-bbce-437b-b79c-ced0f279b226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Labels converted for regression!\n",
      "y_train_reg exists: True\n",
      "y_test_reg exists: True\n"
     ]
    }
   ],
   "source": [
    "# ✅ Convert classification labels into numeric regression values\n",
    "y_train_reg = y_train.astype(float)\n",
    "y_test_reg = y_test.astype(float)\n",
    "\n",
    "print(\"✅ Labels converted for regression!\")\n",
    "print(f\"y_train_reg exists: {'y_train_reg' in globals()}\")  # ✅ Fixed Syntax Error\n",
    "print(f\"y_test_reg exists: {'y_test_reg' in globals()}\")  # ✅ Fixed Syntax Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb26558-88f1-47f0-8839-5f0958cf34fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# ✅ Train SVR\n",
    "svr = SVR()\n",
    "svr.fit(train_features, y_train_reg)\n",
    "\n",
    "# ✅ Make Predictions\n",
    "y_svr_pred = svr.predict(test_features)\n",
    "\n",
    "# ✅ Compute MAE\n",
    "print(f'SVR Regression MAE: {mean_absolute_error(y_test_reg, y_svr_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c451dc6-bbc9-4af5-9b77-0cfcb742ed46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Debugging SVR Issue...\n",
      "train_features exists: False\n",
      "test_features exists: False\n",
      "y_train_reg exists: False\n",
      "y_test_reg exists: False\n",
      "❌ Variable Missing: name 'train_features' is not defined\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 Debugging SVR Issue...\")\n",
    "\n",
    "# ✅ Check if `train_features` & `test_features` exist\n",
    "print(f\"train_features exists: {'train_features' in globals()}\")  \n",
    "print(f\"test_features exists: {'test_features' in globals()}\")  \n",
    "\n",
    "# ✅ Check if regression labels exist\n",
    "print(f\"y_train_reg exists: {'y_train_reg' in globals()}\")  \n",
    "print(f\"y_test_reg exists: {'y_test_reg' in globals()}\")  \n",
    "\n",
    "# ✅ Check the shape of each dataset\n",
    "try:\n",
    "    print(f\"train_features shape: {train_features.shape}\")  \n",
    "    print(f\"test_features shape: {test_features.shape}\")  \n",
    "    print(f\"y_train_reg shape: {y_train_reg.shape}\")  \n",
    "    print(f\"y_test_reg shape: {y_test_reg.shape}\")  \n",
    "except NameError as e:\n",
    "    print(f\"❌ Variable Missing: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23352737-1290-4c97-bbbb-8a048083a6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 42ms/step - accuracy: 0.3195 - loss: 1.8432 - val_accuracy: 0.5283 - val_loss: 1.3217\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step - accuracy: 0.5489 - loss: 1.2635 - val_accuracy: 0.5907 - val_loss: 1.1605\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step - accuracy: 0.6202 - loss: 1.0681 - val_accuracy: 0.6442 - val_loss: 1.0265\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - accuracy: 0.6654 - loss: 0.9472 - val_accuracy: 0.6781 - val_loss: 0.9408\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step - accuracy: 0.6984 - loss: 0.8629 - val_accuracy: 0.6890 - val_loss: 0.9155\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step\n",
      "✅ Feature extraction completed!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# ✅ Reload CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize images\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()  # Flatten labels\n",
    "\n",
    "# ✅ Rebuild the trained CNN\n",
    "def create_cnn():\n",
    "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)  # Feature extraction layer\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name=\"feature_layer\")(x)  # ✅ Feature Layer\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(x)  # ✅ Output Layer\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ✅ Train the CNN Model Again\n",
    "cnn_model = create_cnn()\n",
    "cnn_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# ✅ Extract Features using the trained CNN\n",
    "feature_extractor = models.Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(\"feature_layer\").output)\n",
    "\n",
    "# ✅ Get extracted features for both training and test sets\n",
    "train_features = feature_extractor.predict(x_train, batch_size=64)\n",
    "test_features = feature_extractor.predict(x_test, batch_size=64)\n",
    "\n",
    "print(\"✅ Feature extraction completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef52fb4a-c78e-491c-bdfa-c1ae194b047c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Labels converted for regression!\n",
      "y_train_reg exists: True\n",
      "y_test_reg exists: True\n"
     ]
    }
   ],
   "source": [
    "# ✅ Convert classification labels into numeric regression values\n",
    "y_train_reg = y_train.astype(float)\n",
    "y_test_reg = y_test.astype(float)\n",
    "\n",
    "print(\"✅ Labels converted for regression!\")\n",
    "print(f\"y_train_reg exists: {'y_train_reg' in globals()}\")  \n",
    "print(f\"y_test_reg exists: {'y_test_reg' in globals()}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03984e17-4357-4d79-bc71-748e3040e604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checking Variables Again...\n",
      "train_features exists: True\n",
      "test_features exists: True\n",
      "y_train_reg exists: True\n",
      "y_test_reg exists: True\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 Checking Variables Again...\")\n",
    "\n",
    "print(f\"train_features exists: {'train_features' in globals()}\")  \n",
    "print(f\"test_features exists: {'test_features' in globals()}\")  \n",
    "print(f\"y_train_reg exists: {'y_train_reg' in globals()}\")  \n",
    "print(f\"y_test_reg exists: {'y_test_reg' in globals()}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3d3f547-a760-4732-8cb7-0ccbba3d1788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature scaling completed for SVR!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ✅ Normalize extracted features\n",
    "scaler = StandardScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_features)\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "\n",
    "print(\"✅ Feature scaling completed for SVR!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f04e69c3-a970-4d7c-9fba-655f37ef5af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 43ms/step - accuracy: 0.3056 - loss: 1.8746 - val_accuracy: 0.4828 - val_loss: 1.4301\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step - accuracy: 0.5341 - loss: 1.3139 - val_accuracy: 0.5508 - val_loss: 1.2763\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.5988 - loss: 1.1332 - val_accuracy: 0.6123 - val_loss: 1.1170\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step - accuracy: 0.6422 - loss: 1.0278 - val_accuracy: 0.6352 - val_loss: 1.0463\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step - accuracy: 0.6684 - loss: 0.9395 - val_accuracy: 0.6346 - val_loss: 1.0616\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step\n",
      "✅ Feature extraction completed!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# ✅ Reload CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize images\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()  # Flatten labels\n",
    "\n",
    "# ✅ Rebuild the trained CNN\n",
    "def create_cnn():\n",
    "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)  # Feature extraction layer\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name=\"feature_layer\")(x)  # ✅ Feature Layer\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(x)  # ✅ Output Layer\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ✅ Train the CNN Model Again\n",
    "cnn_model = create_cnn()\n",
    "cnn_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# ✅ Extract Features using the trained CNN\n",
    "feature_extractor = models.Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(\"feature_layer\").output)\n",
    "\n",
    "# ✅ Get extracted features for both training and test sets\n",
    "train_features = feature_extractor.predict(x_train, batch_size=64)\n",
    "test_features = feature_extractor.predict(x_test, batch_size=64)\n",
    "\n",
    "print(\"✅ Feature extraction completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab7efcce-115b-4004-87aa-8801e30876a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Labels converted for regression!\n"
     ]
    }
   ],
   "source": [
    "# ✅ Convert classification labels into numeric regression values\n",
    "y_train_reg = y_train.astype(float)\n",
    "y_test_reg = y_test.astype(float)\n",
    "\n",
    "print(\"✅ Labels converted for regression!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1145ed03-e046-463e-921e-12cb1ac94a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checking Variables Again...\n",
      "train_features exists: True\n",
      "test_features exists: True\n",
      "y_train_reg exists: True\n",
      "y_test_reg exists: True\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 Checking Variables Again...\")\n",
    "\n",
    "print(f\"train_features exists: {'train_features' in globals()}\")  \n",
    "print(f\"test_features exists: {'test_features' in globals()}\")  \n",
    "print(f\"y_train_reg exists: {'y_train_reg' in globals()}\")  \n",
    "print(f\"y_test_reg exists: {'y_test_reg' in globals()}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cb4090a-9765-47e2-b349-042f3588cc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature scaling completed for LASSO!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ✅ Normalize extracted features\n",
    "scaler = StandardScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_features)\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "\n",
    "print(\"✅ Feature scaling completed for LASSO!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09168c40-9b91-4046-9705-71fbcc0f5665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO Regression MAE: 1.9787\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# ✅ Train LASSO Regression\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(train_features_scaled, y_train_reg)\n",
    "\n",
    "# ✅ Make Predictions\n",
    "y_lasso_pred = lasso.predict(test_features_scaled)\n",
    "\n",
    "# ✅ Compute MAE\n",
    "print(f'LASSO Regression MAE: {mean_absolute_error(y_test_reg, y_lasso_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7adc5b13-2972-4a92-9254-dd0a3549510d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ✅ Classification results\n",
    "classifiers = ['Random Forest', 'k-NN', 'Naïve Bayes', ]\n",
    "accuracy = [68.18, 65.61,58.79]  # Set 0 for models that didn't run\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(classifiers, accuracy, color=['blue', 'green', 'red', 'purple', 'gray'])\n",
    "plt.xlabel(\"Classifier\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Classification Performance Comparison\")\n",
    "plt.ylim(0, 100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73002bc5-5a36-4f8c-8b83-c6924f4bd73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ✅ Regression results\n",
    "regressors = ['ANN', 'XGBoost', 'k-NN', 'Linear Regression', 'LASSO', ]\n",
    "mae_scores = [1.07, 1.45,1.81, 1.81, 1.97]  # Set 0 for missing models\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(regressors, mae_scores, color=['blue', 'orange', 'green', 'red', 'purple', 'brown', 'gray'])\n",
    "plt.xlabel(\"Regressor\")\n",
    "plt.ylabel(\"Mean Absolute Error (MAE)\")\n",
    "plt.title(\"Regression Performance Comparison (Lower is Better)\")\n",
    "plt.ylim(0, 3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "422e6035-7d44-4602-8cf2-f89558a9e84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SWAGA\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', kernel_regularizer=l2(0.01), input_shape=(224,224,3)),\n",
    "    Conv2D(64, (3,3), activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dense(10, activation='softmax')  # Output layer for classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23706813-afac-47bc-9cb0-f0e9badb482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),\n",
    "    Dropout(0.3),  # Drops 30% of neurons\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # Drops 50% of neurons\n",
    "    Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ef62f1b-3dda-4ec4-8f6f-0f2a9e1b0e21",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'path_to_train_data/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[0;32m      3\u001b[0m datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[0;32m      4\u001b[0m     rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m, \n\u001b[0;32m      5\u001b[0m     rotation_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     horizontal_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      9\u001b[0m )\n\u001b[1;32m---> 11\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath_to_train_data/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1138\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1122\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1136\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1137\u001b[0m ):\n\u001b[1;32m-> 1138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:453\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m    452\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 453\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    455\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'path_to_train_data/'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\"path_to_train_data/\", target_size=(224,224), batch_size=32, class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b827bb-1bfc-4d58-8f0f-1f57f48225ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6957e5f-15be-4772-8195-40b23209c2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
